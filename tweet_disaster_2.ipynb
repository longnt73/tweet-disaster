{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "2644  So you have a new weapon that can cause un-ima...       1\n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0\n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1\n",
       "132   Aftershock back to school kick off was great. ...       0\n",
       "6845  in response to trauma Children of Addicts deve...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweet_disaster/train.csv')\n",
    "df = df[['text', 'target']]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the first few rows of the training set\n",
    "train_df.head()\n",
    "\n",
    "# Print the first few rows of the validation set\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['courageous', 'honest', 'analysis', 'need', 'use', 'atomic', 'bomb', '1945', 'hiroshima70', 'japanese', 'military', 'refused', 'surrender']\n",
      "6090\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Courageous and honest analysis of need to use ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[courageous, honest, analysis, need, use, atom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>@ZachZaidman @670TheScore wld b a shame if tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>[zachzaidman, 670thescore, wld, b, shame, golf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>Tell @BarackObama to rescind medals of 'honor'...</td>\n",
       "      <td>1</td>\n",
       "      <td>[tell, barackobama, rescind, medals, honor, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>Worried about how the CA drought might affect ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[worried, ca, drought, might, affect, extreme,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>@YoungHeroesID Lava Blast &amp;amp; Power Red #Pan...</td>\n",
       "      <td>0</td>\n",
       "      <td>[youngheroesid, lava, blast, amp, power, red, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "4996  Courageous and honest analysis of need to use ...       1   \n",
       "3263  @ZachZaidman @670TheScore wld b a shame if tha...       0   \n",
       "4907  Tell @BarackObama to rescind medals of 'honor'...       1   \n",
       "2855  Worried about how the CA drought might affect ...       1   \n",
       "4716  @YoungHeroesID Lava Blast &amp; Power Red #Pan...       0   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "4996  [courageous, honest, analysis, need, use, atom...  \n",
       "3263  [zachzaidman, 670thescore, wld, b, shame, golf...  \n",
       "4907  [tell, barackobama, rescind, medals, honor, gi...  \n",
       "2855  [worried, ca, drought, might, affect, extreme,...  \n",
       "4716  [youngheroesid, lava, blast, amp, power, red, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.length = 0\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token.lower() not in self.stopwords]\n",
    "        \n",
    "        # Convert tokens to lowercase\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "        self.length += len(tokens)\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "    def preprocess_dataframe(self, df):\n",
    "        df['preprocessed_text'] = df['text'].apply(self.preprocess_text)\n",
    "        return df\n",
    "\n",
    "train_df = DataPreprocessor().preprocess_dataframe(train_df)\n",
    "val_df = DataPreprocessor().preprocess_dataframe(val_df)\n",
    "\n",
    "print(train_df['preprocessed_text'].iloc[0])\n",
    "print(len(train_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    \n",
    "    def build_vocab(self, df):\n",
    "        for index, row in df.iterrows():\n",
    "            for word in row['preprocessed_text']:\n",
    "                self.add_word(word)\n",
    "    \n",
    "    def transform_text(self, words):\n",
    "        tokens = []\n",
    "        for word in words:\n",
    "            if word in self.word2idx:\n",
    "                tokens.append(self.word2idx[word])\n",
    "        return tokens\n",
    "    \n",
    "    def transform_df(self, df):\n",
    "        df['transformed_text'] = df['text'].apply(self.transform_text)\n",
    "        return df\n",
    "    \n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.build_vocab(train_df)\n",
    "vocab.build_vocab(val_df)\n",
    "\n",
    "# print(f\"Length of vocabulary: {len(vocab)}\")\n",
    "# print(f\"Most common words: {vocab.word2idx}\")\n",
    "\n",
    "train_df = vocab.transform_df(train_df)\n",
    "val_df = vocab.transform_df(val_df)\n",
    "\n",
    "class Padder:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "    \n",
    "    def fit(self, df):\n",
    "        self.max_len = 0\n",
    "        for index, row in df.iterrows():\n",
    "            if len(row['transformed_text']) > self.max_len:\n",
    "                self.max_len = len(row['transformed_text'])\n",
    "    \n",
    "    def transform(self, df):\n",
    "        transformed_text = []\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['transformed_text']\n",
    "            if len(text) < self.max_len:\n",
    "                text = np.append(text, [self.pad_idx] * (self.max_len - len(text)))\n",
    "            else:\n",
    "                text = text[:self.max_len]\n",
    "            # print(len(text), self.max_len)\n",
    "            transformed_text.append(text)\n",
    "        df['padded_text'] = transformed_text\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "# Pad the sequences in the dataframe\n",
    "pad_idx = len(vocab)\n",
    "padder = Padder(pad_idx)\n",
    "padder.fit(train_df)\n",
    "padder.fit(val_df)\n",
    "train_df = padder.transform(train_df)\n",
    "val_df = padder.transform(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longnt2\\AppData\\Local\\Temp\\ipykernel_25444\\1908110286.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  input = torch.tensor(train_df['padded_text'].iloc[:2].tolist())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 69]), torch.Size([2, 69, 100]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor(train_df['padded_text'].iloc[:2].tolist())\n",
    "input.shape\n",
    "\n",
    "embedder = nn.Embedding(len(vocab) + 1, 100)\n",
    "output = embedder(input)\n",
    "\n",
    "input.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([  233,  3460,  2601,  2239,   233,  1400,  3566,  1400,  2239,  1400,\n",
       "           6289,  4344,  1400,  2239,  2239,   233,  2239,  1267,    16,  1400,\n",
       "            289,  1198,   442,    81,  3460,  3566,   290,  3569,  3188,  1400,\n",
       "           2239,  2239,  6289,  3460,  3460,  2239,  4344,   233,  2239,   233,\n",
       "           3460,  3460,  2239,  1400,  2239,  3460,  3566,  3188,  1267,  3566,\n",
       "           3188, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,\n",
       "          17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971],\n",
       "         dtype=torch.int32),\n",
       "  tensor(1)),\n",
       " (tensor([  233,  3460,  2601,  2239,   233,  1400,  3566,  1400,  2239,  1400,\n",
       "           6289,  4344,  1400,  2239,  2239,   233,  2239,  1267,    16,  1400,\n",
       "            289,  1198,   442,    81,  3460,  3566,   290,  3569,  3188,  1400,\n",
       "           2239,  2239,  6289,  3460,  3460,  2239,  4344,   233,  2239,   233,\n",
       "           3460,  3460,  2239,  1400,  2239,  3460,  3566,  3188,  1267,  3566,\n",
       "           3188, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,\n",
       "          17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971],\n",
       "         dtype=torch.int32),\n",
       "  tensor(1)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataloader\n",
    "class DisasterTweetsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.df['padded_text'].iloc[index]\n",
    "        target = self.df['target'].iloc[index]\n",
    "        return torch.tensor(text), torch.tensor(target)\n",
    "\n",
    "train_dataset = DisasterTweetsDataset(train_df)\n",
    "val_dataset = DisasterTweetsDataset(val_df)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataset[0], train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,107,857 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "num_epochs = 10\n",
    "model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m         val_running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, train_loader, val_loader, num_epochs, device, clip)\u001b[0m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get the outputs\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels)\n",
      "File \u001b[1;32md:\\OneDrive - tapdoanxangdau\\PLX\\BI\\Projects\\statistic\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive - tapdoanxangdau\\PLX\\BI\\Projects\\statistic\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 10\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embedded)\n\u001b[0;32m     12\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(torch\u001b[38;5;241m.\u001b[39mcat((hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,:,:], hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\OneDrive - tapdoanxangdau\\PLX\\BI\\Projects\\statistic\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive - tapdoanxangdau\\PLX\\BI\\Projects\\statistic\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\OneDrive - tapdoanxangdau\\PLX\\BI\\Projects\\statistic\\env\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive - tapdoanxangdau\\PLX\\BI\\Projects\\statistic\\env\\Lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the training function\n",
    "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs, device, clip=5):\n",
    "    # Initialize the running values for printing training loss and validation loss\n",
    "    running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    \n",
    "    model.train_losses = []\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # For each batch in the dataloader\n",
    "        for i, (tweets, labels) in enumerate(train_loader):\n",
    "            # Zero out the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get the outputs\n",
    "            outputs = model(tweets)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            \n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip the gradients\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the running loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Print the epoch, batch, loss\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch: [{}/{}],\\tStep: [{}/{}],\\tLoss: {}'.format(\n",
    "                    epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Validate the model\n",
    "        model.eval()\n",
    "        \n",
    "        # For each batch in the dataloader\n",
    "        for i, (tweets, labels) in enumerate(val_loader):\n",
    "            # Get the outputs\n",
    "            outputs = model(tweets)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            # calculate accuracy\n",
    "            pred = torch.round(torch.sigmoid(outputs.squeeze()))\n",
    "            correct_tensor = pred.eq(labels.view_as(pred))\n",
    "            correct = np.squeeze(correct_tensor.numpy())\n",
    "            # calculate test accuracy for each object class\n",
    "            # for i in range(len(labels)):\n",
    "            #     label = labels[i]\n",
    "            #     class_correct[label] += correct[i].item()\n",
    "\n",
    "            \n",
    "            # Update the running loss\n",
    "            val_running_loss += loss.item()\n",
    "        \n",
    "        # Print the epoch, training loss, validation loss\n",
    "        print('Epoch: [{}/{}],\\tTraining Loss: {},\\tValidation Loss: {},\\tAccuracy: {}'.format(\n",
    "            epoch+1, num_epochs, running_loss/len(train_loader), val_running_loss/len(val_loader), np.mean(correct)))\n",
    "        \n",
    "        # Append the training loss and validation loss\n",
    "        model.train_losses.append(running_loss/len(train_loader))\n",
    "        model.val_losses.append(val_running_loss/len(val_loader))\n",
    "        \n",
    "        # Reset the running loss\n",
    "        running_loss = 0.0\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train(model, criterion, optimizer, train_loader, val_loader, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses\n",
    "plt.plot(model.train_losses, label='Training loss')\n",
    "plt.plot(model.val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision on validation set\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    for i, (tweets, labels) in enumerate(val_loader):\n",
    "        outputs = model(tweets)\n",
    "        y_pred.extend(torch.round(torch.sigmoid(outputs.squeeze())).tolist())\n",
    "        y_true.extend(labels.tolist())\n",
    "    print('precision: {}'.format(precision_score(y_true, y_pred, zero_division=1)))\n",
    "    print('recall: {}'.format(recall_score(y_true, y_pred)))\n",
    "    print('f1: {}'.format(f1_score(y_true, y_pred)))\n",
    "    print('confusion matrix: {}'.format(confusion_matrix(y_true, y_pred)))\n",
    "\n",
    "evaluate(model, train_loader)\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the test dataset\n",
    "test_df = pd.read_csv('tweet_disaster/test.csv')\n",
    "test_df = test_df[['text']]\n",
    "test_df = DataPreprocessor().preprocess_dataframe(test_df)\n",
    "test_df = vocab.transform_df(test_df)\n",
    "test_df = pad_sequences(test_df, max_len)\n",
    "test_vectors = torch.FloatTensor(np.array(test_df['padded_text'].tolist()))\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_vectors)\n",
    "    predictions = np.round(torch.sigmoid(predictions).numpy()).astype(int).reshape(-1)\n",
    "\n",
    "# Create a dataframe with the tweet ids and their predictions\n",
    "submission_df = pd.read_csv('tweet_disaster/sample_submission.csv')\n",
    "submission_df['target'] = predictions\n",
    "submission_df.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
